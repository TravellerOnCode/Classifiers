{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hackerearth_Mother's_Day [MULTI-CLASS TEXT CLASSIFICATION - GloVe ].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjAe1Wy1Np2r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2dd86a92-5180-4a0f-fdd2-8101e83c5396"
      },
      "source": [
        "!gsutil cp gs://cloud-training-demos/courses/machine_learning/deepdive/09_sequence/text_classification/glove.6B.200d.txt glove.6B.200d.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/09_sequence/text_classification/glove.6B.200d.txt...\n",
            "\\ [1 files][661.3 MiB/661.3 MiB]                                                \n",
            "Operation completed over 1 objects/661.3 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhJv2GNMN5l9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e8031f42-7dc8-4f6b-c5d9-858e49c90cd7"
      },
      "source": [
        "import pandas as pd\n",
        "import unicodedata\n",
        "import os\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pM0kRotN5uC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fd9d1d6-23ce-4e9f-d616-314b6410b36c"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWHm26A4N5kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm,trange\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CQM8lB_Oy2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79d4de6a-6c94-466c-b3ea-9b932d5aa33a"
      },
      "source": [
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    # set: this is always the case on Kaggle.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRzfuY3HOy4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkPe0GV_Oy9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kld15Uq-OzAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_save = data\n",
        "data = data[[\"id\",\"original_text\",\"sentiment_class\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJV0ku9uOzDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4emHjbMROy7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "\n",
        "collection = contraction_mapping.keys()\n",
        "\n",
        "def expand_words(s):\n",
        "    #unicode_data = s\n",
        "    #w = unicodedata.normalize('NFKD', unicode_data).encode('ASCII', 'ignore')\n",
        "    #w = str(w)[2:len(w)-1]\n",
        "    s = unicodedata.normalize('NFKD', s).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    words = []\n",
        "    s = list(s.split(' '))\n",
        "    for i in s:\n",
        "      if i in collection:\n",
        "          ch = contraction_mapping[i]\n",
        "      else:\n",
        "          ch = i\n",
        "      words.append(ch)\n",
        "\n",
        "    str1 = \"\"\n",
        "    for i in words:\n",
        "      str1 = str1 + \" \" + i\n",
        "    str1.lstrip()\n",
        "    #str1.trim()\n",
        "    return str1\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsxaNHDrO_k5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(text):\n",
        "    # fill the missing entries and convert them to lower case\n",
        "    text = text.fillna(\"fillna\").str.lower()\n",
        "    #remove all special characters\n",
        "    text = text.map(lambda x: re.sub('[^A-Za-z0-9]+',' ',str(x)))\n",
        "    # replace the newline characters with space \n",
        "    text = text.map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
        "    text = text.map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
        "    # remove usernames and links\n",
        "    text = text.map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n",
        "    text = text.map(lambda x: re.sub(\"\\(http://.*?\\s\\(http://.*\\)\",'',str(x)))\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CwO8RcyO_om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIiXmJrCO_q5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "d2bb0091-1321-4cdd-924f-d20910b9bef2"
      },
      "source": [
        "#data['original_text'] = [clean(i) for i in data['original_text']]\n",
        "data['original_text'] = [expand_words(i) for i in data.original_text]\n",
        "\n",
        "#data['original_text'] = [clean(i) for i in data['original_text']]\n",
        "data['original_text'] = clean(data['original_text'])\n",
        "\n",
        "#Converting the Labels 0 -> Negative , 1 - > Neutral 2 -> Positive \n",
        "data[\"sentiment_class\"] = [i+1 for i in data.sentiment_class]\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original_text</th>\n",
              "      <th>sentiment_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.245025e+18</td>\n",
              "      <td>happy mothersday to all you amazing mothers o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.245759e+18</td>\n",
              "      <td>happy mothers day mum i am sorry i cannot be ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.246087e+18</td>\n",
              "      <td>happy mothers day to all this doing a mothers...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.244803e+18</td>\n",
              "      <td>happy mothers day to this beautiful woman roy...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.244876e+18</td>\n",
              "      <td>remembering the 3 most amazing ladies who mad...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ... sentiment_class\n",
              "0  1.245025e+18  ...               1\n",
              "1  1.245759e+18  ...               1\n",
              "2  1.246087e+18  ...               0\n",
              "3  1.244803e+18  ...               1\n",
              "4  1.244876e+18  ...               0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjNzi7CbO_w9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxuiaTUAO_4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e1ea8f4d-fcff-4152-e45b-4b69a27b215d"
      },
      "source": [
        "#Number of Samples per class\n",
        "data.sentiment_class.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1701\n",
              "0     769\n",
              "2     765\n",
              "Name: sentiment_class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-FZDYheO_jl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "56063ff3-91a7-41e4-906d-3dec774267b4"
      },
      "source": [
        "#Plotting every class data in numbers\n",
        "sns.catplot(x='sentiment_class',data=data,kind='count')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f62ac4179b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0lwJAV3Oy0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_0 = data.loc[data['sentiment_class']==0]\n",
        "data_2 = data.loc[data['sentiment_class']==2]\n",
        "\n",
        "\n",
        "#Oversampling the data\n",
        "data_new = pd.concat([data,data_0,data_2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkgzak1YPZGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "3110fe86-0d32-42e3-9236-e98bd8302d06"
      },
      "source": [
        "#Plotting every class data in numbers\n",
        "sns.catplot(x='sentiment_class',data=data_new,kind='count')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f6301508cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGJ686xePZKh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "88c793d7-d40e-43e7-9000-eea0a54be239"
      },
      "source": [
        "data_train = data_new\n",
        "data_train = shuffle(data_train)\n",
        "\n",
        "data_train.sentiment_class.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1701\n",
              "0    1538\n",
              "2    1530\n",
              "Name: sentiment_class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0A0iYBrPZRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpnsTudYPZVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2 = pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEf6uEwRPZPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "34df76a2-d444-44cb-d2f7-bd3184c9c46e"
      },
      "source": [
        "#data['original_text'] = [clean(i) for i in data['original_text']]\n",
        "data2['original_text'] = [expand_words(i) for i in data2.original_text]\n",
        "\n",
        "#data['original_text'] = [clean(i) for i in data['original_text']]\n",
        "data2['original_text'] = clean(data2['original_text'])\n",
        "\n",
        "data_test = data2\n",
        "data_test.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original_text</th>\n",
              "      <th>lang</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>original_author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.246628e+18</td>\n",
              "      <td>3 yeah i once cooked potatoes when i was 3 ye...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>LToddWood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.245898e+18</td>\n",
              "      <td>happy mother s day to all the mums step mums ...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>iiarushii</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.244717e+18</td>\n",
              "      <td>i love the people from the uk however when i ...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>andreaanderegg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ... original_author\n",
              "0  1.246628e+18  ...       LToddWood\n",
              "1  1.245898e+18  ...       iiarushii\n",
              "2  1.244717e+18  ...  andreaanderegg\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp6mvDELURM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = data_test.original_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeMD517jT7pP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X = data_train.original_text\n",
        "Y = data_train.sentiment_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7wS-D04PZM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYCk9-atUH9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oS-P1YrTcd3",
        "colab_type": "text"
      },
      "source": [
        "#Bekar Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8z0iNL1PZI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 20000\n",
        "embedding_dim = 200\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn_jBlE1WPUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-fW-ncsPxL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfMcBSq4J1YI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "768501a0-a60f-4bfc-df42-23d42edab46f"
      },
      "source": [
        "len(word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14838"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdhAArMYVwyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_sequences = tokenizer.texts_to_sequences(X)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(x_test)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-rXMCPYTgUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(training_padded, Y, \n",
        "                                                            random_state=42, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jylEYgoTkAb",
        "colab_type": "text"
      },
      "source": [
        "#Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNUzE-iTPxV1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "670abdcd-28de-4c13-f190-fbff51b1ba07"
      },
      "source": [
        "embeddings_index = {}\n",
        "\"\"\"\n",
        "f = open('glove.6B.200d.txt','r',encoding='utf-8')\n",
        "for line in tqdm(f):\n",
        "    values = line.split(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray([float(val) for val in values[1:]])\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\"\"\"\n",
        "with open('glove.6B.200d.txt','r',encoding='utf-8') as f:\n",
        "    for line in f:  # Every line contains word followed by the vector value\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfeQfr17PxZy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cfd22ff-bd8a-4450-de75-36925421d634"
      },
      "source": [
        "num_tokens = min(len(word_index) + 1, vocab_size)\n",
        "#num_tokens = len(word_index) + 2\n",
        "embedding_dim = 200\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 7323 words (7515 misses)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB4qp2YIPxUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7aa204f-96da-4b3a-8610-c2888cdc84ce"
      },
      "source": [
        "print(num_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF84dk9URWXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Need this block to get it to work with TensorFlow 2.x\n",
        "import numpy as np\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "x_val = np.array(x_val)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "testing_padded = np.array(testing_padded)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SDCKcnmPxS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    input_dim=num_tokens,\n",
        "              output_dim=embedding_dim,\n",
        "              input_length=max_length,\n",
        "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2DWQvNbkYf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#BEST MODEL\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "int_sequences_input = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "x = layers.Dropout(0.5)(embedded_sequences)\n",
        "x = layers.Conv1D(128, 3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(3)(x)\n",
        "#x = layers.Conv1D(128, 3, activation=\"relu\")(x)\n",
        "#x = layers.MaxPooling1D(3)(x)\n",
        "x = layers.Conv1D(128, 3, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "preds = layers.Dense(3, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(int_sequences_input, preds)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvto3W4ngcHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    input_dim=num_tokens,\n",
        "              output_dim=embedding_dim,\n",
        "              input_length=max_length,\n",
        "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0It5oVmsRWST",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "70031e01-1b00-4344-e446-53db7ba46256"
      },
      "source": [
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "int_sequences_input = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "#x = layers.SpatialDropout1D(0.3)(embedded_sequences)\n",
        "#x = layers.Bidirectional(layers.GRU(200, return_sequences=True))(x)\n",
        "#x = layers.GlobalAveragePooling1D()(embedded_sequences)\n",
        "x = layers.Dropout(0.5)(embedded_sequences)\n",
        "x = layers.Conv1D(128, 3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(3)(x)\n",
        "#x = layers.Conv1D(128, 3, activation=\"relu\")(x)\n",
        "#x = layers.MaxPooling1D(3)(x)\n",
        "x = layers.Conv1D(128, 3, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "#x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "preds = layers.Dense(3, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(int_sequences_input, preds)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_20 (InputLayer)        [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_9 (Embedding)      (None, None, 200)         2967800   \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, None, 200)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_30 (Conv1D)           (None, None, 128)         76928     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_13 (MaxPooling (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_31 (Conv1D)           (None, None, 128)         49280     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_15 (Glo (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 3,102,459\n",
            "Trainable params: 134,659\n",
            "Non-trainable params: 2,967,800\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rwb-JRoRWa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd0eG85xnTrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "optimizer = tf.keras.optimizers.RMSprop()#, epsilon=1e-08) #, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        " \"\"\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1eBwBA0ZAPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk8ys23Kjc8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "9f74d8fa-74e9-45b1-be0c-bfd2d408d075"
      },
      "source": [
        "n_steps = x_train.shape[0] // BATCH_SIZE\n",
        "model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=20, steps_per_epoch=n_steps, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "119/119 [==============================] - 1s 6ms/step - loss: 1.1333 - acc: 0.3330 - val_loss: 1.0998 - val_acc: 0.3522\n",
            "Epoch 2/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.1012 - acc: 0.3545 - val_loss: 1.1007 - val_acc: 0.3323\n",
            "Epoch 3/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.1013 - acc: 0.3566 - val_loss: 1.0978 - val_acc: 0.3532\n",
            "Epoch 4/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0997 - acc: 0.3603 - val_loss: 1.1015 - val_acc: 0.3344\n",
            "Epoch 5/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0992 - acc: 0.3574 - val_loss: 1.0982 - val_acc: 0.3501\n",
            "Epoch 6/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0995 - acc: 0.3534 - val_loss: 1.0976 - val_acc: 0.3522\n",
            "Epoch 7/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0987 - acc: 0.3598 - val_loss: 1.0981 - val_acc: 0.3522\n",
            "Epoch 8/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0992 - acc: 0.3582 - val_loss: 1.0981 - val_acc: 0.3522\n",
            "Epoch 9/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0994 - acc: 0.3555 - val_loss: 1.0983 - val_acc: 0.3491\n",
            "Epoch 10/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0993 - acc: 0.3600 - val_loss: 1.0979 - val_acc: 0.3522\n",
            "Epoch 11/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0980 - acc: 0.3534 - val_loss: 1.0974 - val_acc: 0.3522\n",
            "Epoch 12/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0991 - acc: 0.3534 - val_loss: 1.0970 - val_acc: 0.3564\n",
            "Epoch 13/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0986 - acc: 0.3537 - val_loss: 1.0972 - val_acc: 0.3532\n",
            "Epoch 14/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0965 - acc: 0.3627 - val_loss: 1.0934 - val_acc: 0.3553\n",
            "Epoch 15/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0921 - acc: 0.3674 - val_loss: 1.0915 - val_acc: 0.3616\n",
            "Epoch 16/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0870 - acc: 0.3743 - val_loss: 1.0836 - val_acc: 0.4119\n",
            "Epoch 17/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0826 - acc: 0.3812 - val_loss: 1.0837 - val_acc: 0.3753\n",
            "Epoch 18/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0730 - acc: 0.4018 - val_loss: 1.0770 - val_acc: 0.3847\n",
            "Epoch 19/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0639 - acc: 0.4124 - val_loss: 1.0634 - val_acc: 0.4088\n",
            "Epoch 20/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0519 - acc: 0.4195 - val_loss: 1.0569 - val_acc: 0.4403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f62a5d0b048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AfPQ5OyRWV0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "a293797f-6985-4387-cc78-647ccb1c7f78"
      },
      "source": [
        "#BEST RESULTS\n",
        "n_steps = x_train.shape[0] // BATCH_SIZE\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=20, steps_per_epoch=n_steps, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "119/119 [==============================] - 1s 6ms/step - loss: 1.1318 - acc: 0.3325 - val_loss: 1.0989 - val_acc: 0.3428\n",
            "Epoch 2/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.1047 - acc: 0.3529 - val_loss: 1.1028 - val_acc: 0.3208\n",
            "Epoch 3/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0999 - acc: 0.3550 - val_loss: 1.0978 - val_acc: 0.3449\n",
            "Epoch 4/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.1006 - acc: 0.3532 - val_loss: 1.0981 - val_acc: 0.3459\n",
            "Epoch 5/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.1017 - acc: 0.3547 - val_loss: 1.0948 - val_acc: 0.3606\n",
            "Epoch 6/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0977 - acc: 0.3603 - val_loss: 1.1005 - val_acc: 0.3260\n",
            "Epoch 7/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0992 - acc: 0.3635 - val_loss: 1.0982 - val_acc: 0.3459\n",
            "Epoch 8/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0980 - acc: 0.3616 - val_loss: 1.0985 - val_acc: 0.3459\n",
            "Epoch 9/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0961 - acc: 0.3563 - val_loss: 1.1003 - val_acc: 0.3449\n",
            "Epoch 10/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0961 - acc: 0.3566 - val_loss: 1.0995 - val_acc: 0.3375\n",
            "Epoch 11/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0956 - acc: 0.3603 - val_loss: 1.1001 - val_acc: 0.3532\n",
            "Epoch 12/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0928 - acc: 0.3706 - val_loss: 1.0949 - val_acc: 0.3637\n",
            "Epoch 13/20\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 1.0845 - acc: 0.3865 - val_loss: 1.0925 - val_acc: 0.3585\n",
            "Epoch 14/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0682 - acc: 0.4058 - val_loss: 1.0866 - val_acc: 0.3721\n",
            "Epoch 15/20\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 1.0631 - acc: 0.4055 - val_loss: 1.0693 - val_acc: 0.4130\n",
            "Epoch 16/20\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 1.0486 - acc: 0.4370 - val_loss: 1.0528 - val_acc: 0.4025\n",
            "Epoch 17/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0375 - acc: 0.4407 - val_loss: 1.0436 - val_acc: 0.4308\n",
            "Epoch 18/20\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 1.0120 - acc: 0.4555 - val_loss: 1.0495 - val_acc: 0.4371\n",
            "Epoch 19/20\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 1.0054 - acc: 0.4610 - val_loss: 1.0159 - val_acc: 0.4518\n",
            "Epoch 20/20\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 0.9772 - acc: 0.5067 - val_loss: 0.9873 - val_acc: 0.4518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f49fe0a67f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osrbQTjuRWQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "n_steps = x_val.shape[0] // BATCH_SIZE\n",
        "train_history_2 = model.fit(\n",
        "    valid_dataset.repeat(),\n",
        "    steps_per_epoch=n_steps,\n",
        "    epochs=2*2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMqho32tPxKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMZj0bKgbEWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F6zz8KUbEf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(testing_padded)\n",
        "y_pred2 = [np.argmax(i) for i in y_pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfnzgtvIbEZw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "09c2c7ee-1768-4e88-a646-7df9e8b16c3d"
      },
      "source": [
        "y_pred3 = [i-1 for i in y_pred2]\n",
        "print(y_pred3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, -1, -1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 1, 0, -1, 1, 0, -1, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, -1, 0, 0, -1, -1, 0, -1, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, -1, 0, -1, 1, 0, 1, -1, -1, 0, 0, 0, 0, 0, 0, 1, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, -1, -1, 0, 0, -1, -1, -1, 0, 0, 1, 0, -1, 0, 1, 0, -1, 1, 0, -1, -1, 1, 0, 0, 0, 0, -1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, -1, 1, 0, 0, 0, 0, 0, -1, 0, -1, 0, 1, 1, -1, 1, -1, 0, 0, 1, 1, 0, -1, -1, 1, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 1, 0, 0, -1, 1, 0, 0, 0, -1, -1, -1, -1, 0, 0, -1, 1, 0, -1, 1, -1, 0, 0, 1, -1, 1, -1, 0, 0, -1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 1, 0, 0, -1, 1, 1, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 1, -1, 0, 0, 1, 1, 0, 0, -1, 1, 0, 0, 0, 0, -1, 0, 1, -1, 0, 0, 0, -1, -1, 0, 0, 0, 0, -1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 1, -1, 0, 0, 0, -1, 0, -1, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 1, 0, 0, -1, 0, 0, 0, 0, 1, -1, 0, 0, 0, 0, 0, 0, 1, -1, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, -1, 0, 0, -1, -1, 0, 0, -1, 0, 0, 0, 0, 1, 0, 0, 0, 0, -1, 0, 0, -1, 0, -1, 1, 1, 0, 0, 1, -1, 1, 0, 0, 0, 1, 0, 0, 1, -1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, -1, 0, 0, -1, 1, -1, 0, 0, 0, 1, -1, 1, 0, 1, -1, -1, 0, 0, 0, 0, -1, 0, 0, 0, 1, 0, 1, 1, 0, 0, -1, 0, 0, 1, 1, 0, 0, -1, 0, 1, 0, 0, 0, 0, 0, 0, -1, 0, 0, 1, 0, 1, -1, -1, 0, 0, 0, 0, 0, 1, 0, 0, -1, -1, -1, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 1, -1, 0, 0, 1, -1, 0, 0, -1, 0, 1, 1, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, -1, 0, 1, 0, -1, 0, 1, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, -1, 0, 0, 0, 0, -1, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, -1, 0, 0, 0, 1, 0, 1, -1, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, -1, 1, 0, 0, 0, 1, -1, 0, 0, 0, 1, 0, -1, -1, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 1, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, 1, 0, -1, 1, 0, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, -1, -1, 0, 1, 1, -1, 1, 0, 0, 0, 1, -1, 0, 0, -1, 0, -1, 1, -1, 0, 0, -1, -1, 0, 0, 0, 0, -1, -1, 1, 0, 0, 1, 0, -1, 1, -1, 0, 0, 0, 1, -1, -1, 0, -1, -1, 0, 0, 0, -1, 1, -1, -1, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, -1, 0, 0, 0, -1, 0, 0, 0, 0, -1, 0, 0, 0, -1, 0, 0, 1, -1, -1, -1, 0, 0, 0, 0, -1, 0, -1, 0, 0, -1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, -1, 0, -1, 1, -1, 0, 1, -1, 0, 0, 0, -1, 1, 0, 0, -1, 0, 1, -1, 0, 0, 0, -1, 0, 0, 0, -1, 0, 0, 0, -1, -1, 0, 0, -1, -1, 0, -1, 0, 1, 0, -1, -1, 0, -1, -1, -1, 0, 1, 1, 0, 0, 1, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, -1, -1, 1, 0, 0, -1, 1, 0, -1, 0, 0, 0, -1, 0, -1, 0, 1, 1, 1, 0, -1, 0, -1, 0, -1, 0, -1, 0, 0, 0, -1, -1, 0, 0, 0, 1, 0, -1, 0, 1, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 1, 1, 0, -1, 0, -1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, -1, 0, 0, 1, 0, 0, 0, 0, -1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, -1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, 1, 1, 0, 0, 0, 0, -1, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, -1, -1, 0, 0, 0, -1, 0, 0, 0, -1, 0, -1, 1, -1, 0, 1, 0, 1, -1, 0, 0, 0, -1, -1, 0, 0, 0, -1, 1, 0, 0, 0, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 1, -1, -1, 0, 0, 0, 0, 1, 0, -1, 0, 0, 1, 0, 0, 0, 0, 0, -1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, -1, -1, 1, 0, -1, 0, 0, 0, 0, -1, 1, 0, 0, 0, 1, 1, 1, 0, 0, -1, -1, 0, -1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, -1, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, -1, 1, -1, 0, 0, 0, 0, -1, 0, 1, -1, 1, 0, 0, 0, -1, -1, 0, -1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, -1, 0, 0, 0, 0, 0, 1, 0, 0, 0, -1, 0, 1, 1, 0, 0, -1, 0, 1, 1, 1, 1, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, -1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, -1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, -1, -1, 0, -1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, -1, -1, -1, -1, 0, 0, 1, 1, 0, 0, 0, -1, 0, -1, -1, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLn7DbLpbEUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test_ = data_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFEDT-5VbESN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "for ind in data_test.index:\n",
        "  #data_test_['id,sentiment_class'] = (data_test['id'][ind],y_pred3[ind])\n",
        "  b = (data_test['id'][ind],y_pred3[ind])\n",
        "  #print(ind , '  ',b)\n",
        "  a.append(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_Jzd6pIbQln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "2f4d7385-f7c4-40c0-b353-db3a5abe26ca"
      },
      "source": [
        "df = pd.DataFrame(a,columns=['id','sentiment_class'])\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.246628e+18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.245898e+18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.244717e+18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  sentiment_class\n",
              "0  1.246628e+18                0\n",
              "1  1.245898e+18                0\n",
              "2  1.244717e+18                0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hPfYhJtksbs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e4eca25d-e48c-47a2-f542-a5cb9ad40087"
      },
      "source": [
        "df.sentiment_class.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    894\n",
              "-1    283\n",
              " 1    210\n",
              "Name: sentiment_class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cVJjO9zbQpx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e26e7e5a-a641-4020-e900-3b3a5e7b64c3"
      },
      "source": [
        "\n",
        "#BEST RESULT \n",
        "df.sentiment_class.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    792\n",
              " 1    318\n",
              "-1    277\n",
              "Name: sentiment_class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZjzGy9ubQj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('submission2300.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOhdWPRRbEP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}